{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets begin by importing pandas, numpy and matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, lets load our dataset\n",
    "df_train = pd.read_csv('zimmat_train.csv', parse_dates = ['join_date']) #parse_dates to change the dtype from object to datetime.\n",
    "df_test = pd.read_csv('zimmat_test.csv', parse_dates = ['join_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>join_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_category_code</th>\n",
       "      <th>P5DA</th>\n",
       "      <th>RIBP</th>\n",
       "      <th>...</th>\n",
       "      <th>AHXO</th>\n",
       "      <th>BSTQ</th>\n",
       "      <th>FM3X</th>\n",
       "      <th>K6QO</th>\n",
       "      <th>QBOL</th>\n",
       "      <th>JWFN</th>\n",
       "      <th>JZ9D</th>\n",
       "      <th>J9JW</th>\n",
       "      <th>GHYX</th>\n",
       "      <th>ECY3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4WKQSBB</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1987</td>\n",
       "      <td>1X1H</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP5S02H</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1981</td>\n",
       "      <td>UAOD</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2YKDILJ</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>1991</td>\n",
       "      <td>748L</td>\n",
       "      <td>QZYX</td>\n",
       "      <td>90QI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2S9E81J</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1990</td>\n",
       "      <td>1X1H</td>\n",
       "      <td>BP09</td>\n",
       "      <td>56SI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BHDYVFT</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1990</td>\n",
       "      <td>748L</td>\n",
       "      <td>NO3L</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  join_date sex marital_status  birth_year branch_code  \\\n",
       "0  4WKQSBB 2019-01-02   F              M        1987        1X1H   \n",
       "1  CP5S02H 2019-01-06   F              M        1981        UAOD   \n",
       "2  2YKDILJ 2013-01-06   M              U        1991        748L   \n",
       "3  2S9E81J 2019-01-08   M              M        1990        1X1H   \n",
       "4  BHDYVFT 2019-01-08   M              M        1990        748L   \n",
       "\n",
       "  occupation_code occupation_category_code  P5DA  RIBP  ...  AHXO  BSTQ  FM3X  \\\n",
       "0            2A7I                     T4MS     0     0  ...     0     0     0   \n",
       "1            2A7I                     T4MS     0     0  ...     0     0     0   \n",
       "2            QZYX                     90QI     0     0  ...     0     0     0   \n",
       "3            BP09                     56SI     0     0  ...     0     0     0   \n",
       "4            NO3L                     T4MS     0     0  ...     0     0     0   \n",
       "\n",
       "   K6QO  QBOL  JWFN  JZ9D  J9JW  GHYX  ECY3  \n",
       "0     1     0     0     0     0     0     0  \n",
       "1     1     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     1  \n",
       "3     1     0     0     0     0     0     0  \n",
       "4     0     0     0     1     1     0     0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now, lets explore our data\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>join_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_category_code</th>\n",
       "      <th>P5DA</th>\n",
       "      <th>RIBP</th>\n",
       "      <th>...</th>\n",
       "      <th>AHXO</th>\n",
       "      <th>BSTQ</th>\n",
       "      <th>FM3X</th>\n",
       "      <th>K6QO</th>\n",
       "      <th>QBOL</th>\n",
       "      <th>JWFN</th>\n",
       "      <th>JZ9D</th>\n",
       "      <th>J9JW</th>\n",
       "      <th>GHYX</th>\n",
       "      <th>ECY3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F86J5PC</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1984</td>\n",
       "      <td>94KC</td>\n",
       "      <td>DZRV</td>\n",
       "      <td>90QI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H6141K3</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1996</td>\n",
       "      <td>1X1H</td>\n",
       "      <td>J9SY</td>\n",
       "      <td>90QI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RBAYUXZ</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>F</td>\n",
       "      <td>W</td>\n",
       "      <td>1968</td>\n",
       "      <td>UAOD</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KCBILBQ</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1989</td>\n",
       "      <td>94KC</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSEC1ZJ</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1982</td>\n",
       "      <td>UAOD</td>\n",
       "      <td>0KID</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  join_date sex marital_status  birth_year branch_code  \\\n",
       "0  F86J5PC 2018-01-12   M              M        1984        94KC   \n",
       "1  H6141K3 2019-01-10   M              M        1996        1X1H   \n",
       "2  RBAYUXZ 2020-01-01   F              W        1968        UAOD   \n",
       "3  KCBILBQ 2019-01-02   M              M        1989        94KC   \n",
       "4  LSEC1ZJ 2020-01-02   F              M        1982        UAOD   \n",
       "\n",
       "  occupation_code occupation_category_code  P5DA  RIBP  ...  AHXO  BSTQ  FM3X  \\\n",
       "0            DZRV                     90QI     0     0  ...     0     0     0   \n",
       "1            J9SY                     90QI     0     0  ...     0     0     0   \n",
       "2            2A7I                     T4MS     0     0  ...     0     0     0   \n",
       "3            2A7I                     T4MS     0     0  ...     0     0     0   \n",
       "4            0KID                     T4MS     0     0  ...     0     0     0   \n",
       "\n",
       "   K6QO  QBOL  JWFN  JZ9D  J9JW  GHYX  ECY3  \n",
       "0     0     0     0     0     0     0     0  \n",
       "1     1     0     0     0     0     0     0  \n",
       "2     1     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0  \n",
       "4     0     0     0     1     0     0     0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID X PCODE</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F86J5PC X P5DA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F86J5PC X RIBP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F86J5PC X 8NN1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F86J5PC X 7POT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F86J5PC X 66FJ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID X PCODE  Label\n",
       "0  F86J5PC X P5DA      0\n",
       "1  F86J5PC X RIBP      0\n",
       "2  F86J5PC X 8NN1      0\n",
       "3  F86J5PC X 7POT      0\n",
       "4  F86J5PC X 66FJ      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29132, 29) (10000, 29) (210000, 2)\n"
     ]
    }
   ],
   "source": [
    "#checking the shape of our dataset\n",
    "print(df_train.shape, df_test.shape, submit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets store the insurance products id in a multidimensional array, we will be using them during melting\n",
    "\"\"\"\n",
    "We have to melt our data in order to adjust it to the format of our Samplesubmission format\n",
    "\"\"\"\n",
    "train_products = df_train[['P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ',\n",
    "                          'LJR9', 'N2MW', 'AHXO', 'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', \n",
    "                          'GHYX', 'ECY3']]\n",
    "\n",
    "test_products = df_test[['P5DA', 'RIBP', '8NN1', '7POT', '66FJ', 'GYSR', 'SOP4', 'RVSZ', 'PYUQ',\n",
    "                          'LJR9', 'N2MW', 'AHXO', 'BSTQ', 'FM3X', 'K6QO', 'QBOL', 'JWFN', 'JZ9D', 'J9JW', \n",
    "                          'GHYX', 'ECY3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To make analysis of data in the table easier, we can reshape the data into a more computer-friendly form using the\n",
    "melt(). This method unpivots a dataframe from wide format to long format.\n",
    "\"\"\"\n",
    "#Transformation of Axis\n",
    "df_train = df_train.melt(id_vars=df_train.columns[:8], value_vars=train_products, var_name = 'PCODE', value_name ='Label')\n",
    "\n",
    "df_test = df_test.melt(id_vars=df_test.columns[:8], value_vars=test_products, var_name = 'PCODE', value_name ='Label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create a merger, this will help us when we are trying to split our concatenated data\n",
    "df_train['combiner'] = 'X'\n",
    "#notice that we didnt create for test, this will set all test enteries in this column to NA(which will in turn make spliting easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, lets concatenate the test and train data together\n",
    "full_data = pd.concat([df_train, df_test], sort = False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>join_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_category_code</th>\n",
       "      <th>PCODE</th>\n",
       "      <th>Label</th>\n",
       "      <th>combiner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>622528</th>\n",
       "      <td>ZS02Q14</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1974</td>\n",
       "      <td>94KC</td>\n",
       "      <td>2A7I</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>RIBP</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229890</th>\n",
       "      <td>V4K84G1</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1974</td>\n",
       "      <td>E5SW</td>\n",
       "      <td>31JW</td>\n",
       "      <td>90QI</td>\n",
       "      <td>RVSZ</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44198</th>\n",
       "      <td>UPJTNSY</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1982</td>\n",
       "      <td>748L</td>\n",
       "      <td>6E4H</td>\n",
       "      <td>90QI</td>\n",
       "      <td>RIBP</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217692</th>\n",
       "      <td>8C978WC</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>1978</td>\n",
       "      <td>XX25</td>\n",
       "      <td>SST3</td>\n",
       "      <td>56SI</td>\n",
       "      <td>RVSZ</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414925</th>\n",
       "      <td>DBDS1DH</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>1990</td>\n",
       "      <td>E5SW</td>\n",
       "      <td>0OJM</td>\n",
       "      <td>T4MS</td>\n",
       "      <td>K6QO</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466305</th>\n",
       "      <td>V020CLD</td>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1969</td>\n",
       "      <td>UAOD</td>\n",
       "      <td>0B60</td>\n",
       "      <td>JD7X</td>\n",
       "      <td>JWFN</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23126</th>\n",
       "      <td>1MZANI9</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1980</td>\n",
       "      <td>UAOD</td>\n",
       "      <td>SST3</td>\n",
       "      <td>56SI</td>\n",
       "      <td>P5DA</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204157</th>\n",
       "      <td>IYGN3DY</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1988</td>\n",
       "      <td>BOAS</td>\n",
       "      <td>U37O</td>\n",
       "      <td>90QI</td>\n",
       "      <td>RVSZ</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810983</th>\n",
       "      <td>KBC7EUN</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>1982</td>\n",
       "      <td>UAOD</td>\n",
       "      <td>BPSA</td>\n",
       "      <td>90QI</td>\n",
       "      <td>GHYX</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344624</th>\n",
       "      <td>810D9QL</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>1994</td>\n",
       "      <td>UAOD</td>\n",
       "      <td>SST3</td>\n",
       "      <td>56SI</td>\n",
       "      <td>AHXO</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  join_date sex marital_status  birth_year branch_code  \\\n",
       "622528  ZS02Q14 2020-01-02   M              M        1974        94KC   \n",
       "229890  V4K84G1 2018-01-10   M              M        1974        E5SW   \n",
       "44198   UPJTNSY 2016-01-03   M              M        1982        748L   \n",
       "217692  8C978WC 2018-01-05   F              S        1978        XX25   \n",
       "414925  DBDS1DH 2019-01-07   F              M        1990        E5SW   \n",
       "466305  V020CLD 2016-01-11   M              M        1969        UAOD   \n",
       "23126   1MZANI9 2018-01-06   M              M        1980        UAOD   \n",
       "204157  IYGN3DY 2019-01-08   M              M        1988        BOAS   \n",
       "810983  KBC7EUN 2018-01-06   F              S        1982        UAOD   \n",
       "344624  810D9QL 2018-01-04   M              M        1994        UAOD   \n",
       "\n",
       "       occupation_code occupation_category_code PCODE  Label combiner  \n",
       "622528            2A7I                     T4MS  RIBP      0      NaN  \n",
       "229890            31JW                     90QI  RVSZ      1        X  \n",
       "44198             6E4H                     90QI  RIBP      0        X  \n",
       "217692            SST3                     56SI  RVSZ      1        X  \n",
       "414925            0OJM                     T4MS  K6QO      1        X  \n",
       "466305            0B60                     JD7X  JWFN      0        X  \n",
       "23126             SST3                     56SI  P5DA      0        X  \n",
       "204157            U37O                     90QI  RVSZ      1        X  \n",
       "810983            BPSA                     90QI  GHYX      0      NaN  \n",
       "344624            SST3                     56SI  AHXO      0        X  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets get a sample(random) of our entire dataset\n",
    "full_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Distribution:\n",
      "**************************************************\n",
      "0    545419\n",
      "1     66353\n",
      "Name: Label, dtype: int64\n",
      "**************************************************\n",
      "Testing Label Distribution:\n",
      "0    197147\n",
      "1     12853\n",
      "Name: Label, dtype: int64\n",
      "**************************************************\n",
      "Submission Label Distribution:\n",
      "0    197147\n",
      "1     12853\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Now, lets check the distribution of the labels(insurance products)...checking for inbalances\n",
    "print('Training Label Distribution:')\n",
    "print('**' * 25)\n",
    "print(df_train['Label'].value_counts())\n",
    "print('**' * 25)\n",
    "print('Testing Label Distribution:')\n",
    "print(df_test['Label'].value_counts())\n",
    "print('**' * 25)\n",
    "print('Submission Label Distribution:')\n",
    "print(submit['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(611772, 10) (210000, 9) (210000, 2)\n"
     ]
    }
   ],
   "source": [
    "#now, lets split our full_data back... the combiner will make the job easier(incase there is any mixup)\n",
    "df_train = full_data[full_data.combiner.notnull()].reset_index(drop = True) #we know that df_train has X in the combiner column\n",
    "df_test = full_data[full_data.combiner.isna()].reset_index(drop =  True) # we also know that the test values are nan in combiner\n",
    "\n",
    "df_train = df_train.drop('combiner', axis = 1)\n",
    "df_test = df_test.drop(['Label', 'combiner'], axis = 1)\n",
    "\n",
    "print(df_train.shape, df_test.shape, submit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the submission format, we may need to create a new column to meet the requirements\n",
    "df_train['ID X PCODE'] = df_train['ID'] + ' X ' + df_train['PCODE']\n",
    "df_test['ID X PCODE'] = df_test['ID'] + ' X ' + df_test['PCODE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets try to rearange the columns, this can make our submission easier\n",
    "df_train = df_train[['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
    "                    'occupation_code', 'occupation_category_code', 'PCODE', 'ID X PCODE', 'Label']]\n",
    "\n",
    "df_test = df_test[['ID', 'join_date', 'sex', 'marital_status', 'birth_year', 'branch_code',\n",
    "                    'occupation_code', 'occupation_category_code', 'PCODE', 'ID X PCODE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories Not in TestPCODE  []\n",
      "Categories Not in TrainPCODE  []\n",
      "**********************************************************************\n",
      "Categories Not in Testoccupation_code  ['IE90', 'Q0LY', 'JSAX', '6XXU', '8HRZ', 'OQMY', 'INEJ', 'VZN9', 'UC7E', 'PSUY', 'WSRG', 'JQH3', 'LGTN', '738L', 'QQUP', '2XZ1', 'CAAV', 'LLLH', 'W1X2', 'DHSN', 'IX8T', '2US6', 'ZWPL', 'MEFQ', '9B5B', 'JUIP', 'BFD1', 'A4ZC', 'IMHI', 'E5PF', 'GZA8', '3YQ1', 'PJR4', 'NDL9', 'PPNK', '2686', '5LNN', '374O', 'URYD', 'M0WG', 'KBWO', 'ONY7', 'VYSA', 'KUPK', 'R7GL', 'HSVE', 'BER4', '6SKY', 'RH2K', 'ZHC2', 'W3ZV', 'FLXH', 'UYDZ', 'YJXM', '59QM']\n",
      "Categories Not in Trainoccupation_code  ['0ZND', '8CHJ', '9F96', 'HSI5', '93OJ', 'BIA0', 'E2MJ', 'JBJP', '0FOI']\n",
      "**********************************************************************\n",
      "Categories Not in Testbranch_code  []\n",
      "Categories Not in Trainbranch_code  []\n",
      "**********************************************************************\n",
      "Categories Not in Testoccupation_category_code  []\n",
      "Categories Not in Trainoccupation_category_code  []\n",
      "**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "#lets check for uniqueness amongst the categorical columns in train and test data\n",
    "cat_cols_spec = ['PCODE', 'occupation_code', 'branch_code', 'occupation_category_code']\n",
    "for col in cat_cols_spec:\n",
    "    df_train_col = df_train[col].unique() #get the unique categories in that particular column\n",
    "    df_test_col = df_test[col].unique()\n",
    "    print('Categories Not in Test' + col + ' ', [i for i in df_train_col if i not in df_test_col])\n",
    "    print('Categories Not in Train' + col + ' ',  [i for i in df_test_col if i not in df_train_col])\n",
    "    print('**'* 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we see that there are some categories in the training data that are absent from the test data... vise-versa\n",
    "\"\"\"\n",
    "we will be label encoding, but most importantly, we will be taking notes of some important\n",
    "concepts like df.factorize.\n",
    "df.factorize is useful for obtaining a numeric representation of an array when all that matters is \n",
    "identifying distinct values(which is what we want in this case, since there is no order.)\n",
    "another beautiful thing is that None values take the value of -1 in the label.\n",
    "label, uniques = pd.factorize()...we dont need the uniques, so we will be using label,_\n",
    "THIS IS THE BEST WAY SO FAR TO ENCODE UNEQUAL CATEGORIES IN CATEGORICAL FEATURES\n",
    "\"\"\"\n",
    "import gc\n",
    "#verbose is set to true to get warnings and log options\n",
    "def leb_encode(df_train, df_test, columns, verbose = True):\n",
    "    for col in columns:\n",
    "        full_comb = pd.concat([df_train[col], df_test[col]], axis = 0)#we concattenated the relevant columns\n",
    "        full_comb,_ = full_comb.factorize(sort=True)\n",
    "        nam = col\n",
    "        if full_comb.max()>32000: #int32 and int16 have different memory capacity(we are encoding the ID(we can have large values))\n",
    "            df_train[nam] = full_comb[:len(df_train)].astype('int32')#we are assigning the encoded colunmms back to our dataframe\n",
    "            df_test[nam] = full_comb[len(df_train):].astype('int32')\n",
    "        else:\n",
    "            df_train[nam] = full_comb[:len(df_train)].astype('int16')\n",
    "            df_test[nam] = full_comb[len(df_train):].astype('int16')\n",
    "        del full_comb\n",
    "        x=gc.collect()#garbage collector...we are triggering it because we want to free a lot of objects\n",
    "        if verbose:\n",
    "            print(nam, ', ', end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID , branch_code , occupation_code , occupation_category_code , PCODE , sex , marital_status , "
     ]
    }
   ],
   "source": [
    "leb_encode(df_train, df_test, ['ID','branch_code', 'occupation_code', 'occupation_category_code', 'PCODE', 'sex', 'marital_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now its time to deal with the date and year attributes\n",
    "#we will start by creating a beautiful function to extract year and date from our date colummn\n",
    "def extract_date(df, column):\n",
    "    \"\"\"df takes a dataframe, column takes a string\"\"\"\n",
    "    df[column+\"_year\"] = df[column].apply(lambda x: x.year)#x will take the date value from the column and lambda applies x.year\n",
    "    df[column+\"_month\"] = df[column].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_date(df_train, 'join_date')\n",
    "extract_date(df_test, 'join_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>join_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_category_code</th>\n",
       "      <th>PCODE</th>\n",
       "      <th>ID X PCODE</th>\n",
       "      <th>Label</th>\n",
       "      <th>join_date_year</th>\n",
       "      <th>join_date_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5384</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>4WKQSBB X P5DA</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13834</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>CP5S02H X P5DA</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3217</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1991</td>\n",
       "      <td>3</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2YKDILJ X P5DA</td>\n",
       "      <td>0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3010</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1990</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2S9E81J X P5DA</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12546</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1990</td>\n",
       "      <td>3</td>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>BHDYVFT X P5DA</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  join_date  sex  marital_status  birth_year  branch_code  \\\n",
       "0   5384 2019-01-02    0               2        1987            0   \n",
       "1  13834 2019-01-06    0               2        1981           11   \n",
       "2   3217 2013-01-06    1               6        1991            3   \n",
       "3   3010 2019-01-08    1               2        1990            0   \n",
       "4  12546 2019-01-08    1               2        1990            3   \n",
       "\n",
       "   occupation_code  occupation_category_code  PCODE      ID X PCODE  Label  \\\n",
       "0               19                         5     15  4WKQSBB X P5DA      0   \n",
       "1               19                         5     15  CP5S02H X P5DA      0   \n",
       "2              185                         1     15  2YKDILJ X P5DA      0   \n",
       "3               82                         0     15  2S9E81J X P5DA      0   \n",
       "4              157                         5     15  BHDYVFT X P5DA      0   \n",
       "\n",
       "   join_date_year  join_date_month  \n",
       "0          2019.0              1.0  \n",
       "1          2019.0              1.0  \n",
       "2          2013.0              1.0  \n",
       "3          2019.0              1.0  \n",
       "4          2019.0              1.0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets write a function to handle birth_year... we would be returning their age\n",
    "def age_birth(df, column):\n",
    "    current_year = 2020\n",
    "    df['age'] = df[column].apply(lambda x: current_year-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the missing values with modes\n",
    "df_train['join_date_year'].fillna(df_train['join_date_year'].mode()[0], inplace=True)\n",
    "df_train['join_date_month'].fillna(df_train['join_date_month'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['join_date_year'].fillna(df_test['join_date_year'].mode()[0], inplace=True)\n",
    "df_test['join_date_month'].fillna(df_test['join_date_month'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_birth(df_train, 'birth_year')\n",
    "age_birth(df_test, 'birth_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>join_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>branch_code</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_category_code</th>\n",
       "      <th>PCODE</th>\n",
       "      <th>ID X PCODE</th>\n",
       "      <th>Label</th>\n",
       "      <th>join_date_year</th>\n",
       "      <th>join_date_month</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5384</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>4WKQSBB X P5DA</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13834</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>CP5S02H X P5DA</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3217</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1991</td>\n",
       "      <td>3</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2YKDILJ X P5DA</td>\n",
       "      <td>0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3010</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1990</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2S9E81J X P5DA</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12546</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1990</td>\n",
       "      <td>3</td>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>BHDYVFT X P5DA</td>\n",
       "      <td>0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  join_date  sex  marital_status  birth_year  branch_code  \\\n",
       "0   5384 2019-01-02    0               2        1987            0   \n",
       "1  13834 2019-01-06    0               2        1981           11   \n",
       "2   3217 2013-01-06    1               6        1991            3   \n",
       "3   3010 2019-01-08    1               2        1990            0   \n",
       "4  12546 2019-01-08    1               2        1990            3   \n",
       "\n",
       "   occupation_code  occupation_category_code  PCODE      ID X PCODE  Label  \\\n",
       "0               19                         5     15  4WKQSBB X P5DA      0   \n",
       "1               19                         5     15  CP5S02H X P5DA      0   \n",
       "2              185                         1     15  2YKDILJ X P5DA      0   \n",
       "3               82                         0     15  2S9E81J X P5DA      0   \n",
       "4              157                         5     15  BHDYVFT X P5DA      0   \n",
       "\n",
       "   join_date_year  join_date_month  age  \n",
       "0          2019.0              1.0   33  \n",
       "1          2019.0              1.0   39  \n",
       "2          2013.0              1.0   29  \n",
       "3          2019.0              1.0   30  \n",
       "4          2019.0              1.0   30  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets drop some columns before we call our classifiers\n",
    "y=df_train['Label']\n",
    "X_train= df_train.drop(['join_date', 'ID X PCODE', 'birth_year', 'Label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit = df_test['ID X PCODE']\n",
    "X_test= df_test.drop(['join_date','ID X PCODE', 'birth_year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((611772, 10), (210000, 10), (611772,))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "clf = lgb.LGBMClassifier()\n",
    "scores = cross_val_score(clf, X_train, y, cv=5, scoring = 'roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9122799 , 0.84374883, 0.76318142, 0.94190652, 0.61386082])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8149954984485305"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we wil need some visualizations to understand our data better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
